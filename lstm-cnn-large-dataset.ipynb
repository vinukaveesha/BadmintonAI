{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220cf31",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-01T08:16:41.863383Z",
     "iopub.status.busy": "2025-04-01T08:16:41.863090Z",
     "iopub.status.idle": "2025-04-01T08:16:56.545088Z",
     "shell.execute_reply": "2025-04-01T08:16:56.544145Z"
    },
    "papermill": {
     "duration": 14.68759,
     "end_time": "2025-04-01T08:16:56.547045",
     "exception": false,
     "start_time": "2025-04-01T08:16:41.859455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import joblib\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         #print(os.path.join(dirname, filename))\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f626e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T08:16:56.553714Z",
     "iopub.status.busy": "2025-04-01T08:16:56.552977Z",
     "iopub.status.idle": "2025-04-01T11:09:59.398825Z",
     "shell.execute_reply": "2025-04-01T11:09:59.398046Z"
    },
    "papermill": {
     "duration": 10382.869672,
     "end_time": "2025-04-01T11:09:59.419634",
     "exception": false,
     "start_time": "2025-04-01T08:16:56.549962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 20  \n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "video_dataset_path = \"/kaggle/input/data-set-updated/data set updated\"\n",
    "output_sequence_path = \"/kaggle/working/sequence_dataset\"\n",
    "\n",
    "# Create output folder structure\n",
    "os.makedirs(output_sequence_path, exist_ok=True)\n",
    "\n",
    "# Process each action category\n",
    "for action in os.listdir(video_dataset_path):\n",
    "    action_path = os.path.join(video_dataset_path, action)\n",
    "    if not os.path.isdir(action_path):\n",
    "        continue\n",
    "\n",
    "    # Create action directory in output\n",
    "    output_action_path = os.path.join(output_sequence_path, action)\n",
    "    os.makedirs(output_action_path, exist_ok=True)\n",
    "\n",
    "    # Process each video\n",
    "    for video_name in tqdm(os.listdir(action_path), desc=f\"Processing {action}\"):\n",
    "        video_path = os.path.join(action_path, video_name)\n",
    "        \n",
    "        # Skip non-video files\n",
    "        if not video_name.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            continue\n",
    "\n",
    "        # Create video-specific folder for frames\n",
    "        video_folder = os.path.join(output_action_path, os.path.splitext(video_name)[0])\n",
    "        os.makedirs(video_folder, exist_ok=True)\n",
    "\n",
    "        # Extract frames with temporal awareness\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Calculate equally spaced frame indices\n",
    "        frame_indices = np.linspace(0, total_frames-1, SEQUENCE_LENGTH, dtype=int)\n",
    "\n",
    "        for idx, frame_idx in enumerate(frame_indices):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                # Preprocess frame\n",
    "                frame = cv2.resize(frame, IMG_SIZE)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                cv2.imwrite(os.path.join(video_folder, f\"frame_{idx:04d}.jpg\"), frame)\n",
    "            else:\n",
    "                # Handle missing frames with black image\n",
    "                black_frame = np.zeros((*IMG_SIZE, 3), dtype=np.uint8)\n",
    "                cv2.imwrite(os.path.join(video_folder, f\"frame_{idx:04d}.jpg\"), black_frame)\n",
    "        \n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ebe319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:09:59.457723Z",
     "iopub.status.busy": "2025-04-01T11:09:59.457494Z",
     "iopub.status.idle": "2025-04-01T11:09:59.466455Z",
     "shell.execute_reply": "2025-04-01T11:09:59.465826Z"
    },
    "papermill": {
     "duration": 0.029316,
     "end_time": "2025-04-01T11:09:59.467633",
     "exception": false,
     "start_time": "2025-04-01T11:09:59.438317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class SequenceGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataset_path, batch_size=8, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.classes = sorted([d for d in os.listdir(dataset_path) \n",
    "                             if os.path.isdir(os.path.join(dataset_path, d))])\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
    "        self.samples = self._prepare_samples(dataset_path)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def _prepare_samples(self, dataset_path):\n",
    "        samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_path = os.path.join(dataset_path, class_name)\n",
    "            for video_folder in os.listdir(class_path):\n",
    "                video_path = os.path.join(class_path, video_folder)\n",
    "                if os.path.isdir(video_path):\n",
    "                    samples.append((video_path, self.class_to_idx[class_name]))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.samples) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_samples = self.samples[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X, y = self._load_batch(batch_samples)\n",
    "        return X, y\n",
    "\n",
    "    def _load_batch(self, batch_samples):\n",
    "        batch_sequences = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for video_path, label in batch_samples:\n",
    "            # Load and sort frames\n",
    "            frame_files = sorted([f for f in os.listdir(video_path) \n",
    "                                if f.endswith('.jpg')])\n",
    "            sequence = []\n",
    "            \n",
    "            for frame_file in frame_files[:SEQUENCE_LENGTH]:\n",
    "                img = cv2.imread(os.path.join(video_path, frame_file))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = img.astype(np.float32) / 255.0\n",
    "                sequence.append(img)\n",
    "            \n",
    "            # Pad if necessary\n",
    "            while len(sequence) < SEQUENCE_LENGTH:\n",
    "                sequence.append(np.zeros_like(sequence[0]))\n",
    "            \n",
    "            batch_sequences.append(sequence)\n",
    "            batch_labels.append(label)\n",
    "        \n",
    "        return np.array(batch_sequences), tf.keras.utils.to_categorical(batch_labels, num_classes=len(self.classes))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fd302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:09:59.505529Z",
     "iopub.status.busy": "2025-04-01T11:09:59.505304Z",
     "iopub.status.idle": "2025-04-01T11:10:02.038783Z",
     "shell.execute_reply": "2025-04-01T11:10:02.038095Z"
    },
    "papermill": {
     "duration": 2.553998,
     "end_time": "2025-04-01T11:10:02.040347",
     "exception": false,
     "start_time": "2025-04-01T11:09:59.486349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_hybrid_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        # TimeDistributed CNN Block 1\n",
    "        TimeDistributed(Conv2D(32, (3,3), activation='relu', padding='same'), input_shape=input_shape),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        TimeDistributed(MaxPooling2D(2,2)),\n",
    "        \n",
    "        # TimeDistributed CNN Block 2\n",
    "        TimeDistributed(Conv2D(64, (3,3), activation='relu', padding='same')),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        TimeDistributed(MaxPooling2D(2,2)),\n",
    "        \n",
    "        # TimeDistributed CNN Block 3\n",
    "        TimeDistributed(Conv2D(128, (3,3), activation='relu', padding='same')),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        TimeDistributed(MaxPooling2D(2,2)),\n",
    "        \n",
    "        # Flatten before LSTM\n",
    "        TimeDistributed(Flatten()),\n",
    "        \n",
    "        # LSTM Layer\n",
    "        LSTM(64, return_sequences=False),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Classifier Head\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize model with parameters\n",
    "SEQUENCE_LENGTH = 20  # Number of frames per sequence\n",
    "IMG_SIZE = (224, 224) # Input image dimensions\n",
    "model = build_hybrid_model(\n",
    "    input_shape=(SEQUENCE_LENGTH, IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "    num_classes=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1606690d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:10:02.080043Z",
     "iopub.status.busy": "2025-04-01T11:10:02.079792Z",
     "iopub.status.idle": "2025-04-01T11:10:02.113434Z",
     "shell.execute_reply": "2025-04-01T11:10:02.112553Z"
    },
    "papermill": {
     "duration": 0.055254,
     "end_time": "2025-04-01T11:10:02.114738",
     "exception": false,
     "start_time": "2025-04-01T11:10:02.059484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "output_sequence_path = \"/kaggle/working/sequence_dataset\"\n",
    "train_path = os.path.join(output_sequence_path, \"train\")\n",
    "val_path = os.path.join(output_sequence_path, \"val\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "# Split dataset (80% train, 20% validation)\n",
    "for class_name in os.listdir(output_sequence_path):\n",
    "    class_path = os.path.join(output_sequence_path, class_name)\n",
    "    \n",
    "    # Skip non-class directories\n",
    "    if not os.path.isdir(class_path) or class_name in [\"train\", \"val\"]:\n",
    "        continue\n",
    "    \n",
    "    # Get all video folders for this class\n",
    "    video_folders = [f for f in os.listdir(class_path)\n",
    "                    if os.path.isdir(os.path.join(class_path, f))]\n",
    "    \n",
    "    # Split videos\n",
    "    train_videos, val_videos = train_test_split(video_folders, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create class directories in train/val\n",
    "    os.makedirs(os.path.join(train_path, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_path, class_name), exist_ok=True)\n",
    "    \n",
    "    # Move video folders to appropriate directories\n",
    "    for video in train_videos:\n",
    "        src = os.path.join(class_path, video)\n",
    "        dst = os.path.join(train_path, class_name, video)\n",
    "        shutil.move(src, dst)\n",
    "        \n",
    "    for video in val_videos:\n",
    "        src = os.path.join(class_path, video)\n",
    "        dst = os.path.join(val_path, class_name, video)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "print(\"Dataset organized into train/val folders!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db03c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:10:02.152678Z",
     "iopub.status.busy": "2025-04-01T11:10:02.152465Z",
     "iopub.status.idle": "2025-04-01T11:10:02.158380Z",
     "shell.execute_reply": "2025-04-01T11:10:02.157812Z"
    },
    "papermill": {
     "duration": 0.026158,
     "end_time": "2025-04-01T11:10:02.159535",
     "exception": false,
     "start_time": "2025-04-01T11:10:02.133377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After organizing the data, initialize generators like this:\n",
    "train_generator = SequenceGenerator(train_path)\n",
    "val_generator = SequenceGenerator(val_path, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65f1b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:10:02.197601Z",
     "iopub.status.busy": "2025-04-01T11:10:02.197368Z",
     "iopub.status.idle": "2025-04-01T11:10:02.205307Z",
     "shell.execute_reply": "2025-04-01T11:10:02.204533Z"
    },
    "papermill": {
     "duration": 0.0282,
     "end_time": "2025-04-01T11:10:02.206607",
     "exception": false,
     "start_time": "2025-04-01T11:10:02.178407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Initialize generators with proper paths\n",
    "train_generator = SequenceGenerator(\n",
    "    os.path.join(output_sequence_path, \"train\"),\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = SequenceGenerator(\n",
    "    os.path.join(output_sequence_path, \"val\"),\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e23599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:10:02.244210Z",
     "iopub.status.busy": "2025-04-01T11:10:02.243962Z",
     "iopub.status.idle": "2025-04-01T11:10:02.247485Z",
     "shell.execute_reply": "2025-04-01T11:10:02.246923Z"
    },
    "papermill": {
     "duration": 0.023593,
     "end_time": "2025-04-01T11:10:02.248553",
     "exception": false,
     "start_time": "2025-04-01T11:10:02.224960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create checkpoint directory\n",
    "checkpoint_dir = os.path.join('/kaggle/working', \"training_checkpoints\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, \n",
    "                         \"epoch_{epoch:02d}_valacc_{val_accuracy:.2f}.keras\"),  # Changed to .keras\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    save_freq='epoch',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba3870",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:10:02.286919Z",
     "iopub.status.busy": "2025-04-01T11:10:02.286699Z",
     "iopub.status.idle": "2025-04-01T11:20:41.603589Z",
     "shell.execute_reply": "2025-04-01T11:20:41.602895Z"
    },
    "papermill": {
     "duration": 639.337632,
     "end_time": "2025-04-01T11:20:41.605066",
     "exception": false,
     "start_time": "2025-04-01T11:10:02.267434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate class weights (now based on training data only)\n",
    "class_counts = np.bincount([label for _, label in train_generator.samples])\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique([label for _, label in train_generator.samples]),\n",
    "    y=[label for _, label in train_generator.samples]\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))  # Correct mapping\n",
    "\n",
    "# In model.fit(), use the dictionary instead of the array\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=10,\n",
    "        class_weight=class_weights_dict,  # FIX: Use the dictionary here\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b81f40e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:20:41.712350Z",
     "iopub.status.busy": "2025-04-01T11:20:41.712088Z",
     "iopub.status.idle": "2025-04-01T11:20:53.269838Z",
     "shell.execute_reply": "2025-04-01T11:20:53.268932Z"
    },
    "papermill": {
     "duration": 11.612547,
     "end_time": "2025-04-01T11:20:53.271089",
     "exception": false,
     "start_time": "2025-04-01T11:20:41.658542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Generate predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(val_generator)):\n",
    "    X, y = val_generator[i]\n",
    "    preds = model.predict(X)\n",
    "    y_true.extend(np.argmax(y, axis=1))\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=val_generator.classes))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=val_generator.classes, \n",
    "           yticklabels=val_generator.classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7013036,
     "sourceId": 11228039,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11057.013807,
   "end_time": "2025-04-01T11:20:56.289214",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-01T08:16:39.275407",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
